---
title: "Tidyverse Essentials - `dplyr`"
subtitle: "The grammar of data wrangling"
author: "Matthew Scott"
date: "2024-07-24"
description: "Data wrangling: solve the most common data manipulation challenges"
categories: [tutorial, r, tidyverse, dplyr, intro]
image: "abstract-art.png"
image-alt: "An abstract sketch whos colours bleed into the canvas"
code-annotations: hover
draft: false
toc: true
---

![Abstract Canvas](abstract-art-wide.png){fig-alt="A cropped version of the main image"}
```{r setup}
#| eval: true
#| echo: false

library(dplyr)
library(ggplot2)
```

## Introduction

dplyr helps manipulate datasets. That is, it can be used to change their shape - the number of rows, columns. As well as having verbs to create new columns.

### Dataset used in this tutorial

We will use the `mpg` dataset from [**ggplot2**]{.text-warning} in this tutorial and run through a lot of the common syntax used to manipulate a table.

:::{.callout-note icon="true" collapse="true"}
## mpg

```{r}
#| eval: true

library(ggplot2)
glimpse(mpg) # <1>
```
1. We can see the column names, their datatype (inside `< >`) and example data in a list-like format. We also get information on the number of rows and columns, the 'shape'
:::

## `select()` & `rename()`

Choose which columns to include or exclude.

`select([df], helper_function([col_1], [col_2]))`

You can wrap the columns in helper functions:

* `contains(match, ignore.case = T)` - column name contains a certain string
* `starts_with(match, ignore.case = T)` - column names start with
* `ends_with(match, ignore.case = T)` - column names end with
* `matches(match, ignore.case = T)` - matches a regular expression
* `num_range(prefix, range, ...)` - names following the pattern e.g. `num_range("Wk", 1:3)`: "Wk1", "Wk2", "Wk3"
* `any_of()` - will select all columns available from a list
* `all_of()` - used for strict selection. Throws an error if one of the columns named in the list aren't present in the dataframe
* `matches()` - exactly matches a certain string
* `everything()` - every other column not specified already
* `where(is.numeric())` - will select all numeric columns (int or dbl). Also `is.character`, `is.factor`, `is.integer`, `is.double`

`rename([new_name] = [old_name])`

```{r select-example}
# selecting column by index (position)

# select columns in position 1-3
select(df, 1:3)
# select columns in position 1-3
select(df, c(2, 5, 7))
# select from the second to last column to the last column
select(df, (ncol(df) -2) : ncol(df))

# selecting columns that contain 'l' (upper or lower case) 
# and renaming 'model' to 'type' etc.
df %>%  
  select(contains('l', ignore.case = T)) %>% 
  rename(type = model, cylinder = cyl)

# select and rename in one call
select(df, 
       mnfc = manufacturer, # <1>
       mod = model, # <1>
       everything()) # <2>

# select all numeric columns plus some extras
mpg %>%
  select(where(is.numeric), # <3>
         mnfc = manufacturer, # <4>
         mod = model) # <4>

# another approach: create a vector and use this with any_of()
numerical_cols <- c('displ', 'year', 'cyl', 'cty', 'hwy')
numerical_df <- df %>% 
  select(any_of(numerical_cols))

# negative selections
df %>% 
  select(-any_of(c(model, displ, cyl))) # <5>
```

1. select and rename in one call
2. select all remaining columns that haven't already been specified
3. this will select all column of data type int or dbl
4. add two additional non-numeric cols to your selection
5. remove any of these columns that appear in the data frame

## `mutate()` & `transmute()`

Create new columns from existing ones.

`mutate([new_col] = [old_col(s) + logic])`

* creates a new column based on the logic provided
* you can create multiple columns at one time
* adds the new col to the df

`transmute([new_col] = [old_col(s) + logic])`

* creates a new column and drops other columns (this can be useful when do machine learning and you don't want the new columns interfering with the model)

Helpful functions for dealing with strings:

| Functions | 
|:------:|
| `as.character()` | 
| `as.date()` | 
| `as.integer()` | 

: {.striped .hover}

**Note** There is also `lubridate` and `hms` packages for working with dates and times that give a lot more flexibility. `stringr` is another useful package commonly used with mutate to extract parts of string columns.

```{r}
#| eval: true
# create 'avg mpg' column and paste together two cols into 'car'
# this will return the full df plus these two new cols
mpg %>% 
    mutate(
         car = paste(manufacturer, model, sep = ' '),
        `avg mpg` = (( cty + hwy ) / 2 ),
         cty, # <1>
        .keep = "none") %>%  # <2>
    head(5)


```
1. We can specify the col name with no calc and it will get included
2. Acts like `transmute` to keep only created columns

Use `.by` to group our selection in a single expression. We return the max avg mpg for each model type:

```{r}
#| eval: true

mpg %>% 
    mutate(`avg mpg` = ((cty+hwy)/2),
           `max avg mpg` = max(`avg mpg`),
           .by = model,
           .keep = "used") # <1>
```
1. Now we keep only columns used in our mutate verb, including those used in the calculations.

### Common usage

Replace existing columns with mutated version of themselves, either by converting the data type or cleaning the column of NAs. Create new columns with mutate.

- `case_when()`
- `case_match()`
- `if_else()`
- `na_if()`

```{r}
# mutate with case_when
mpg %>% 
    mutate(
        "hwy_bins" = case_when(
            hwy < 20 ~ "low",
            between(hwy, 20, 30) ~ "medium",
            hwy > 30 ~ "high",
            TRUE ~ NA_character_
            ))

# mutate with if_else
mpg %>% 
    mutate(
        "is_offroad" = if_else(
            drv == "4", "Y", "N"
        ))

# mutate with na_if() to replace values with NA
mpg %>% 
    mutate(year = na_if(year, "NaN")) # <1>


```
1. if "NaN" present, replace it with NA to help clean the column


### Other mutate verbs

* `mutate_all()` - affects every variable
* `mutate_if()` - affects variables selected with a predicate function
* `mutate_at()` - affects variables selected with a character variable or vars()

```{r}
# This code:
table_sep <- table %>%
  separate(col = date,
           into = c("year", "month", "dayofmonth"),
           sep = "-") %>%
  mutate(month = as.numeric(month), # <1>
         dayofmonth = as.numeric(dayofmonth)) %>% # <1>
  arrange(year, month, dayofmonth)

# is the same as this:
table_sep <- table %>%
  separate(col = date,
           into = c("year", "month", "dayofmonth"),
           sep = "-") %>%
  mutate_at(.vars = c("month", "dayofmonth"), # <2>
            .funs = as.numeric) # <2>
  arrange(year, month, dayofmonth)
```
1. Where we have to specify every column to change data type here...
2. ...we can supply the columns in a list and only have to specify the mutate function once

You can imagine if we had lots of columns to mutate, this would be much more succinct.

:::{.callout-note appearance="simple" icon="true"}
## Note 
It is generally preferred to use `across()` instead of the above verbs. See [Column-wise operations](https://dplyr.tidyverse.org/articles/colwise.html){target="_blank"} for a detailed explanation of this.
:::

You can mutate any column that is.character/is.numeric...:

```{r}
#| eval: true

mpg %>% 
    mutate_if(is.character, stringr::str_to_title) %>% # <1>
    select(is.character) %>% 
    head(4)
```
1. convert all character columns to title case (upper case at start of each word)

### `across()`

`across` works very well with `summarise()` & `mutate()`.

```{r}
#| eval: true

mpg %>% 
    summarise(across(where(is.character), n_distinct)) # <1>
```
1. `across()` is used to apply the summary, `n_distint()`, across the selected columns - in this case all character columns

## `filter()` & `slice()`

### `filter()` 
Used to extract or create a subset of rows based on logical operators
- it will produce a new table

Logical operators to use with `filter()`:

| Operator | Meaning
|:----:| :----:
| `==` | equal to
| `!=` | not equal to
| `<` | less than
| `>` | greater than
| `<=` | less than or equal to
| `>=` | greater than or equal to
| `between()` | between two values (inclusive)
| `!` | not
| `is.na()` | is NA
| `!is.na()` | is not NA
| `%in%` | is in (a vector)
| `|` | or
| `&` | and
| `xor()` | exclusive or - 'one or the other but not both'

: {.striped .hover}

Filtering a table:

```{r}
#| eval: true

# this is the same as '&'
mpg %>% 
    filter(manufacturer == "audi",
           year == 1999) %>%
    head()

```

### `slice()` 
Used to select certain rows of the table based on row position

Related slice functions:

- `slice_head()`
- `slice_tail()`
- `slice_sample()`
- `slice_max()`
- `slice_min()`

```{r}
# select rows 10-20
slice(df, 10:20)

# slice top 10 rows
slice_head(df, n = 10)

# select bottom rows
slice_tail(df, prop = .1) # <1>

# select 10 rows at random from df
slice_sample(df, 10)
# select rows at random based on proportion of df
slice_sample(df, prop = .1)

df %>% slice_max(hwy, n = 10) # <2>
df %>% slice_min(hwy, prop = .1) # <2>
```
1. select the bottom 10% of the df
2. order by the selected column and select the top/bottom rows

:::{.callout-note appearance="simple" icon="true"}
## `slice_sample()` Note 
slice-sample can be done in two main ways, by taking the sampled rows 'out' of the data frame (so when subsequent sample slices are made, they cannot be chosen again), or by 'replacing' the sample (so in subsequent sample slices the same rows can be chosen again).

This is done using the `replace =` argument:

- `df %>% slice_sample(prop = .1, replace = True)`
- `df %>% slice_sample(prop = .1, replace = False)`

`replace = False` is the default.
:::

- You can set a seed for reproducibility. Using the same seed will yield the same random selection each time, useful for code reviews where your results need to be reproduced.

```{r}
# use base r for this
set.seed(200)
```

## `arrange()`

`arrange([data], desc([column_a], [column_b], ...))`

- Sort rows by columns or values that you define
- Analogous to ORDER BY in SQL syntax
- Can wrap columns in `desc()` to arrange in descending order

```{r}
# arrange by year asc
arrange(df, year)
#  arrange by year desc
arrange(df, desc(year))
# arrange by multiple columns
arrange(df, desc(cyl), displ) 

# or using the pipe
df %>% arrange(desc(year))
```

## `distinct()`
`distinct([df], [col_a], [col_b], ...)`

- Removes rows with duplicate values
- Specify columns in distinct to select only those column

```{r}
#| eval: true

# will create a table where the combination 
# of manufacturer and model is distinct
mpg %>% 
  select(manufacturer, model) %>% 
  distinct() # <1>
```
1. Because no columns are specified, `distinct` returns all columns

```{r}
#| eval: true
mpg %>% 
    group_by(model) %>% # <1>
    distinct(manufacturer, .keep_all = T) %>%  # <2>
    head()
```
1. distinct will respect `group_by` and return distinct values for each group
2. `keep_all` will keep the first row of values from all other columns

## `lag()`

- This verb is used to find the previous or next value in a vector
- Use it with mutate to create a new column with this comparison

`lag( [vector/column], n = [int] )`

A scenario where this is useful would be when we have a column of dates and want to filter on only instances where there is an increase from the precious instance (this can be done on integers, dates, time).

We can:
1. use `lag()` in a mutate argument to create a new columns
2. use filter to compare the two columns

In the example below we order the storms dataset by year, month, day & hour to get sequential storms throughout the year. We can then see only storms that occur at a higher latitude throughout the year to help answer a specific question.

```{r}

storms |> 
    summarise(year = min(year),
              month = min(month),
              day = min(day),
              hour = min(hour),
              .by = name) |> 
    arrange(year, month, day, hour) |> 
    mutate(previous_storm = lag(name),
           .keep = "used") |> 
    head(5)

```

